AI工程工具的普及速度远超以往任何软件工程工具。在不到两年的时间内，4个开源AI工程工具（AutoGPT、Stable Diffusion web UI、LangChain、Ollama）在GitHub上的星标数（star）已超过了比特币项目，
并有望超越包括React和Vue在内的最受欢迎的Web开发框架
一、语言模型
1️⃣自回归 (AR) = 猜下一个词——文本生成任务的首选模型，因此比掩码语言模型更受欢迎。
2️⃣掩码 (MLM) = 猜中间的词——常用于情感分析和文本分类等非生成任务
目前最前沿的研究（如 Google 的 T5 或 GLM）尝试把两者结合起来，即：用“填空”的方式去训练，但让模型具备“续写”的能力。
虽然“填空”的模型（如 BERT）在理解复杂句子上很强，但现在的大模型（LLM）主流几乎全是“背诵”架构（自回归）

3️⃣生成式模型 (Generative Model)是一个广义的概念，只要一个模型的目标是学习数据的概率分布，并能生成新的数据，它就叫生成式模型。
它不仅限于文本，还包括图像（如 Midjourney 使用的扩散模型）、音频等。
4️⃣RNN/LSTM/Seq2Seq
5️⃣BERT/Transformer Encoder
6️⃣多数据模态融合-理解图像视频蛋白质结构等-更强大-
传统：一直按照数据模态划分：自然语言处理只处理文本，计算机视觉只处理视觉,情感分析模型无法进行翻译任务。
如今纯文本模型可用于翻译和垃圾邮件检测等任务，纯图像模型可用于目标检测和图像分类，
纯音频模型则可用于语音识别（语音转文本，speech-to-text，STT）和语音合成（文本转语音，text-to-speech，TTS）​。
7️⃣多模态模型-生成式多模态大模型
提示工程-检索增强生成(RAG)-微调


语言模型可以通过自监督的方式进行训练，而许多其他模型则需要监督训练。
1️⃣自监督训练-不需要人工标注-从输入数据中自行推断标签-语言建模就是一种自监督学习-创建更大数据集规模
语言模型可以直接从文本序列中学习，而不需要任何标注。由于文本序列随处可见——书籍、博客文章、新闻报道以及Reddit评论等，因此可以构建大量的训练数据，使语言模型能够扩展为LLM。
——OpenAI使用了一种称为自然语言监督的自监督学习来训练他们的语言-图像模型CLIP（OpenAI，​“CLIP: Connecting text and images”​，2021）​。他们并没有为每张图片手动生成标签，
而是在互联网上寻找同时出现的（图像，文本）对。通过这种方式，他们构建了一个包含4亿个（图像，文本）对的数据集，其规模是ImageNet数据集的400倍，且无人工标注成本。
借助这个数据集，CLIP成为首个不需要额外训练即可泛化到多个图像分类任务的模型。

CLIP并不是生成式模型——它并非被训练用于生成开放式输出。CLIP是一种嵌入模型（embeddingmodel）​，训练目标是生成文本和图像的联合嵌入（jointembedding）​。
目前，你可以将嵌入理解为旨在捕捉原始数据含义的向量。
像CLIP这样的多模态嵌入模型是生成式多模态模型（如Flamingo、LLaVA和Gemini，Gemini之前称为Bard）的基础。
2️⃣监督训练-标注数据-耗时成本高

3️⃣无监督学习-不需要标签。

大数据集搭配大模型训练，大模型拥有更强的学习能力-反之小数据集搭配小模型训练；
把小数据集喂给大模型-浪费计算资源、过拟合;
那把大数据集喂给小模型-欠拟合；

二、质量指标
1️⃣质量指标：衡量聊天机器人回复的质量。延迟指标：包括TTFT（time to first token，首个token响应时间）​、TPOT（time per output token，每个输出token响
应时间）和总延迟。什么样的延迟是可接受的，取决于具体的应用场景。
如果当前所有用户请求都由人工处理，中位响应时间为1小时，那么只要AI的响应比1小时快，可能就算足够好。
成本指标：每次推理请求的成本。其他指标：例如可解释性和公平性。

2️⃣如果你的产品是基于使用他人数据训练的模型构建的，你能确保产品的知识产权始终属于你吗？
许多高度依赖知识产权的公司，比如游戏工作室，都因担心未来可能会失去知识产权而对使用AI持谨慎态度

3️⃣AI工程技术栈
应用开发层-模型开发层-基础设施层
